{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project - extracting legal terms.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMAeuCt3ComE2VvjnSr0G6X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satyaram-k/satyaram_INFO5731_Spring2020/blob/main/Group_4-Caselaw_Access_Project/Extracting_legal_terms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7-DO_yDNG16"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import urllib.request\n",
        "import re\n",
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "\n",
        "# headers requried to open the link\n",
        "\n",
        "header_data = {\n",
        "    'Access-Control-Allow-Origin': '*',\n",
        "    'Access-Control-Allow-Methods': 'GET',\n",
        "    'Access-Control-Allow-Headers': 'Content-Type',\n",
        "    'Access-Control-Max-Age': '3600',\n",
        "    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0',\n",
        "    'Accept-Language': 'en-US, en;q=0.5'\n",
        "}\n",
        "\n",
        "\n",
        "data = []\n",
        "alphabets =  list(string.ascii_uppercase)\n",
        "\n",
        "for i in alphabets:\n",
        "  url = 'https://dictionary.law.com/Default.aspx?letter='\n",
        "  law_dictonary = requests.get(url+i, headers=header_data)\n",
        "  soup = BeautifulSoup(law_dictonary.content,'html.parser')\n",
        "  term = soup.find_all('span',class_='word')\n",
        "  for text in range(0,len(term)):\n",
        "    data.append(term[text].get_text().strip())\n",
        "  \n",
        "\n",
        "df = pd.DataFrame({'term': data})\n",
        "df.to_csv('legal_terms.csv')\n",
        "\n",
        "df\n"
      ]
    }
  ]
}