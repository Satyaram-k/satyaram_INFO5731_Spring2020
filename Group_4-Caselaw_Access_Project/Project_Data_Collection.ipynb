{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project - Data Collection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satyaram-k/satyaram_INFO5731_Spring2020/blob/main/Group_4-Caselaw_Access_Project/Project_Data_Collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import certifi\n",
        "import urllib3\n",
        "from urllib3.exceptions import MaxRetryError\n",
        "from tqdm import tqdm\n",
        "import lzma\n",
        "import json\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "SQi4vvoqxrVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_URL = \"https://api.case.law\"\n",
        "API_VERSION = \"v1\"\n",
        "API_BULK_URL = API_URL + \"/\" + API_VERSION + \"/\" + \"bulk\"\n",
        "DATA_DIR = '/content'\n",
        "API_KEY = \"30983208107a7033ff5df9e18faf9e2559afb528\"\n",
        "CVIOLET = '\\33[35m'\n",
        "CEND = '\\33[0m'\n",
        "CURL = '\\33[4m'\n",
        "\n",
        "def print_info(instruction):\n",
        "    \"\"\"\n",
        "    Colorize print output for instructions\n",
        "    \"\"\"\n",
        "    print(CVIOLET + instruction + CEND)"
      ],
      "metadata": {
        "id": "UdwnTzutw1DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cases_from_bulk(jurisdiction, data_format=\"json\"):\n",
        "    body_format = \"xml\" if data_format == \"xml\" else \"text\"\n",
        "    bulk_url = API_BULK_URL + \"/?body_format=%s&filter_type=jurisdiction\" % body_format\n",
        "    bulk_api_results = requests.get(bulk_url)\n",
        "    found = False\n",
        "\n",
        "    for jur in bulk_api_results.json()['results']:\n",
        "        if jurisdiction in jur['file_name']:\n",
        "            found = True\n",
        "            break\n",
        "\n",
        "    if not found:\n",
        "        raise Exception(\"Jurisdiction not found. Please check spelling.\")\n",
        "\n",
        "    filename = os.path.join(DATA_DIR, jur['file_name'])\n",
        "\n",
        "    http = urllib3.PoolManager(\n",
        "        cert_reqs='CERT_REQUIRED',\n",
        "        ca_certs=certifi.where())\n",
        "\n",
        "    headers = {'AUTHORIZATION': 'Token {}'.format(API_KEY)}\n",
        "    try:\n",
        "        resp = http.request(\"GET\", jur[\"download_url\"],\n",
        "                            preload_content=False,\n",
        "                            headers=headers)\n",
        "    except MaxRetryError as err:\n",
        "        print(\"Writing of file was interrupted.\\n\\n%s\" % err)\n",
        "        return\n",
        "\n",
        "    if resp.status != 200:\n",
        "        raise Exception(\"Something went wrong.\\n\\n%s\" % resp.data)\n",
        "\n",
        "    print_info(\"downloading %s into ../data dir\" % jur['file_name'])\n",
        "    with open(filename, 'wb') as f:\n",
        "        for chunk in tqdm(resp.stream(1024)):\n",
        "            f.write(chunk)\n",
        "\n",
        "    print_info(\"extracting %s into ../data dir\" % jur['file_name'])\n",
        "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall(DATA_DIR)\n",
        "\n",
        "    print_info(\"Done.\")\n",
        "\n",
        "    decompressed_dir = filename.split('.zip')[0]\n",
        "    return os.path.join(decompressed_dir + '/data/data.jsonl.xz')"
      ],
      "metadata": {
        "id": "RCHLQpI8xVIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_and_extract_from_bulk(jurisdiction, data_format=\"json\"):\n",
        "    dir_exists = False\n",
        "    data_format = \"xml\" if data_format == \"xml\" else \"text\"  # xml or json\n",
        "\n",
        "    for filename in os.listdir(DATA_DIR):\n",
        "        if jurisdiction in filename and \"-\" + data_format in filename:\n",
        "            if os.path.exists(os.path.join(DATA_DIR, filename + '/data/data.jsonl.xz')):\n",
        "                dir_exists = True\n",
        "                break\n",
        "\n",
        "    if dir_exists:\n",
        "        dir_path = os.path.join(DATA_DIR, filename)\n",
        "    else:\n",
        "        print_info(\"Getting compressed file for %s from /bulk endpoint.\\nThis might take a while.\" % jurisdiction)\n",
        "        dir_path = get_cases_from_bulk(jurisdiction=jurisdiction, data_format=data_format)\n",
        "\n",
        "    compressed_file = os.path.join(DATA_DIR, dir_path)\n",
        "\n",
        "    return compressed_file\n"
      ],
      "metadata": {
        "id": "br-90fMzwTJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df_to_text(dataframe):\n",
        "  text_list = []\n",
        "  for i in range(0,len(dataframe)):\n",
        "    opinion = ''\n",
        "    for j in range(0,len(dataframe['casebody'][i]['data']['opinions'])):\n",
        "      opinion = opinion + dataframe['casebody'][i]['data']['opinions'][j]['text']\n",
        "    text_list.append(opinion)\n",
        "  return text_list"
      ],
      "metadata": {
        "id": "-m309YSCSuXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Collecting Texas Cases ###\n",
        "compressed_file_tex = get_and_extract_from_bulk(jurisdiction=\"Texas\", data_format=\"json\")\n",
        "\n",
        "# extracting the cases\n",
        "cases_tex = []\n",
        "print(\"File path:\", compressed_file_tex)\n",
        "with lzma.open(compressed_file_tex) as infile:\n",
        "    for line in infile:\n",
        "        record = json.loads(str(line, 'utf-8'))\n",
        "        cases_tex.append(record)\n",
        "\n",
        "print(\"Texas case count: %s\" % len(cases_tex))\n",
        "\n",
        "# loading the cases into a dataframe\n",
        "tex_df = pd.DataFrame(cases_tex)\n",
        "\n",
        "# printing dataframe info\n",
        "tex_df.info()"
      ],
      "metadata": {
        "id": "BBdanHhPymXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Collecting California Cases ###\n",
        "compressed_file_cal = get_and_extract_from_bulk(jurisdiction=\"California\", data_format=\"json\")\n",
        "\n",
        "# extracting the cases\n",
        "cases_cal = []\n",
        "print(\"File path:\", compressed_file_cal)\n",
        "with lzma.open(compressed_file_cal) as infile:\n",
        "    for line in infile:\n",
        "        record = json.loads(str(line, 'utf-8'))\n",
        "        cases_cal.append(record)\n",
        "\n",
        "print(\"California case count: %s\" % len(cases_cal))\n",
        "\n",
        "# loading the cases into a dataframe\n",
        "cal_df = pd.DataFrame(cases_cal)\n",
        "\n",
        "# printing dataframe info\n",
        "cal_df.info()"
      ],
      "metadata": {
        "id": "68I9HpbmSyPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Texas Groups Text #####\n",
        "\n",
        "# Group one [2015-2016]\n",
        "tex_1 = tex_df[(tex_df['decision_date'] >= '2015-01-01') & (tex_df['decision_date'] <= '2016-12-31')]\n",
        "tex_1.reset_index(drop=True, inplace=True)\n",
        "tex_group_1 = df_to_text(tex_1)\n",
        "print('Number of cases in Texas in 2015 & 2016: ', len(tex_group_1))\n",
        "\n",
        "# Group two [2013-2014]\n",
        "tex_2 = tex_df[(tex_df['decision_date'] >= '2013-01-01') & (tex_df['decision_date'] <= '2014-12-31')]\n",
        "tex_2.reset_index(drop=True, inplace=True)\n",
        "tex_group_2 = df_to_text(tex_2)\n",
        "print('Number of cases in Texas in 2013 & 2014: ', len(tex_group_2))\n",
        "\n",
        "# Group three [2011-2012]\n",
        "tex_3 = tex_df[(tex_df['decision_date'] >= '2011-01-01') & (tex_df['decision_date'] <= '2012-12-31')]\n",
        "tex_3.reset_index(drop=True, inplace=True)\n",
        "tex_group_3 = df_to_text(tex_3)\n",
        "print('Number of cases in Texas in 2011 & 2012: ', len(tex_group_3))\n",
        "\n",
        "# Group four [2009-2010]\n",
        "tex_4 = tex_df[(tex_df['decision_date'] >= '2009-01-01') & (tex_df['decision_date'] <= '2010-12-31')]\n",
        "tex_4.reset_index(drop=True, inplace=True)\n",
        "tex_group_4 = df_to_text(tex_4)\n",
        "print('Number of cases in Texas in 2009 & 2010: ', len(tex_group_4))\n",
        "\n",
        "# Group five [2007-2008]\n",
        "tex_5 = tex_df[(tex_df['decision_date'] >= '2007-01-01') & (tex_df['decision_date'] <= '2008-12-31')]\n",
        "tex_5.reset_index(drop=True, inplace=True)\n",
        "tex_group_5 = df_to_text(tex_5)\n",
        "print('Number of cases in Texas in 2007 & 2008: ', len(tex_group_5))"
      ],
      "metadata": {
        "id": "IyndB_1BcoxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### California Groups Text #####\n",
        "\n",
        "# Group one [2015-2016]\n",
        "cal_1 = cal_df[(cal_df['decision_date'] >= '2015-01-01') & (cal_df['decision_date'] <= '2016-12-31')]\n",
        "cal_1.reset_index(drop=True, inplace=True)\n",
        "cal_group_1 = df_to_text(cal_1)\n",
        "print('Number of cases in Californina in 2015 & 2016: ', len(cal_group_1))\n",
        "\n",
        "# Group two [2013-2014]\n",
        "cal_2 = cal_df[(cal_df['decision_date'] >= '2013-01-01') & (cal_df['decision_date'] <= '2014-12-31')]\n",
        "cal_2.reset_index(drop=True, inplace=True)\n",
        "cal_group_2 = df_to_text(cal_2)\n",
        "print('Number of cases in Californina in 2013 & 2014: ', len(cal_group_2))\n",
        "\n",
        "# Group three [2011-2012]\n",
        "cal_3 = cal_df[(cal_df['decision_date'] >= '2011-01-01') & (cal_df['decision_date'] <= '2012-12-31')]\n",
        "cal_3.reset_index(drop=True, inplace=True)\n",
        "cal_group_3 = df_to_text(cal_3)\n",
        "print('Number of cases in Californina in 2011 & 2012: ', len(cal_group_3))\n",
        "\n",
        "# Group four [2009-2010]\n",
        "cal_4 = cal_df[(cal_df['decision_date'] >= '2009-01-01') & (cal_df['decision_date'] <= '2010-12-31')]\n",
        "cal_4.reset_index(drop=True, inplace=True)\n",
        "cal_group_4 = df_to_text(cal_4)\n",
        "print('Number of cases in Californina in 2009 & 2010: ', len(cal_group_4))\n",
        "\n",
        "# Group five [2007-2008]\n",
        "cal_5 = cal_df[(cal_df['decision_date'] >= '2007-01-01') & (cal_df['decision_date'] <= '2008-12-31')]\n",
        "cal_5.reset_index(drop=True, inplace=True)\n",
        "cal_group_5 = df_to_text(cal_5)\n",
        "print('Number of cases in Californina in 2007 & 2008: ', len(cal_group_5))"
      ],
      "metadata": {
        "id": "eAqfr2x5cosF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the data locally\n",
        "\n",
        "import pickle\n",
        "\n",
        "# Texas\n",
        "open_file = open('/content/tex_group_1.pkl', \"wb\")\n",
        "pickle.dump(tex_group_1, open_file)\n",
        "open_file.close()\n",
        "\n",
        "open_file = open('/content/tex_group_2.pkl', \"wb\")\n",
        "pickle.dump(tex_group_2, open_file)\n",
        "open_file.close()\n",
        "\n",
        "open_file = open('/content/tex_group_3.pkl', \"wb\")\n",
        "pickle.dump(tex_group_3, open_file)\n",
        "open_file.close()\n",
        "\n",
        "open_file = open('/content/tex_group_4.pkl', \"wb\")\n",
        "pickle.dump(tex_group_4, open_file)\n",
        "open_file.close()\n",
        "\n",
        "open_file = open('/content/tex_group_5.pkl', \"wb\")\n",
        "pickle.dump(tex_group_5, open_file)\n",
        "open_file.close()\n",
        "\n",
        "# California\n",
        "open_file = open('/content/cal_group_1.pkl', \"wb\")\n",
        "pickle.dump(cal_group_1, open_file)\n",
        "open_file.close()\n",
        "\n",
        "open_file = open('/content/cal_group_2.pkl', \"wb\")\n",
        "pickle.dump(cal_group_2, open_file)\n",
        "open_file.close()\n",
        "\n",
        "open_file = open('/content/cal_group_3.pkl', \"wb\")\n",
        "pickle.dump(cal_group_3, open_file)\n",
        "open_file.close()\n",
        "\n",
        "open_file = open('/content/cal_group_4.pkl', \"wb\")\n",
        "pickle.dump(cal_group_4, open_file)\n",
        "open_file.close()\n",
        "\n",
        "open_file = open('/content/cal_group_5.pkl', \"wb\")\n",
        "pickle.dump(cal_group_5, open_file)\n",
        "open_file.close()"
      ],
      "metadata": {
        "id": "s-GZo7qviNBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # downloading data to local machine\n",
        "# from google.colab import files\n",
        "# files.download('/content/tex_group_1.pkl')\n",
        "# files.download('/content/tex_group_2.pkl')\n",
        "# files.download('/content/tex_group_3.pkl')\n",
        "# files.download('/content/tex_group_4.pkl')\n",
        "# files.download('/content/tex_group_5.pkl')\n",
        "# files.download('/content/cal_group_1.pkl')\n",
        "# files.download('/content/cal_group_2.pkl')\n",
        "# files.download('/content/cal_group_3.pkl')\n",
        "# files.download('/content/cal_group_4.pkl')\n",
        "# files.download('/content/cal_group_5.pkl')"
      ],
      "metadata": {
        "id": "sZkv9JuukKb_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}